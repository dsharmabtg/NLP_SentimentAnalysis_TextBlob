{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More TextBlob functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\dell\\anaconda3_6\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\dell\\anaconda3_6\\lib\\site-packages (from textblob) (3.3)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\anaconda3_6\\lib\\site-packages (from nltk>=3.1->textblob) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\dell\\anaconda3_6\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\dell\\anaconda3_6\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\dell\\anaconda3_6\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\dell\\anaconda3_6\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\dell\\anaconda3_6\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from textblob.taggers import NLTKTagger\n",
    "from textblob.translate import Translator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cmpkey',\n",
       " '_compare',\n",
       " '_create_sentence_objects',\n",
       " '_strkey',\n",
       " 'analyzer',\n",
       " 'classify',\n",
       " 'correct',\n",
       " 'detect_language',\n",
       " 'ends_with',\n",
       " 'endswith',\n",
       " 'find',\n",
       " 'format',\n",
       " 'index',\n",
       " 'join',\n",
       " 'json',\n",
       " 'lower',\n",
       " 'ngrams',\n",
       " 'noun_phrases',\n",
       " 'np_counts',\n",
       " 'np_extractor',\n",
       " 'parse',\n",
       " 'parser',\n",
       " 'polarity',\n",
       " 'pos_tagger',\n",
       " 'pos_tags',\n",
       " 'raw_sentences',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'sentences',\n",
       " 'sentiment',\n",
       " 'sentiment_assessments',\n",
       " 'serialized',\n",
       " 'split',\n",
       " 'starts_with',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'subjectivity',\n",
       " 'tags',\n",
       " 'title',\n",
       " 'to_json',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'tokens',\n",
       " 'translate',\n",
       " 'translator',\n",
       " 'upper',\n",
       " 'word_counts',\n",
       " 'words']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['urgently needed; absolutely necessary', 'performing an essential function in the living body', 'full of spirit', 'manifesting or characteristic of life']\n"
     ]
    }
   ],
   "source": [
    "a = Word(\"vital\")\n",
    "print(a.definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of extreme importance; vital to the resolution of a crisis', 'having crucial relevance', 'of the greatest importance']\n"
     ]
    }
   ],
   "source": [
    "b = Word(\"crucial\")\n",
    "print(b.definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enjoying or showing or marked by joy or pleasure', 'marked by good fortune', 'eagerly disposed to act or to be of service', 'well expressed and to the point']\n"
     ]
    }
   ],
   "source": [
    "c = Word(\"happy\")\n",
    "print(c.definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 0.40303358613217766), ('god', 0.19664138678223186), ('glad', 0.08125677139761647), ('gold', 0.06771397616468039), ('guns', 0.06067172264355363), ('loud', 0.03466955579631636), ('gun', 0.03412784398699892), ('guard', 0.030335861321776816), ('mud', 0.01950162513542795), ('guide', 0.013001083423618635), ('gut', 0.007583965330444204), ('fund', 0.007583965330444204), ('gulf', 0.007042253521126761), ('gout', 0.0065005417118093175), ('thud', 0.005417118093174431), ('gums', 0.004333694474539545), ('gum', 0.0032502708559046588), ('glued', 0.0021668472372697724), ('stud', 0.0016251354279523294), ('guam', 0.0016251354279523294), ('bud', 0.0016251354279523294), ('und', 0.0010834236186348862), ('guy', 0.0010834236186348862), ('gust', 0.0010834236186348862), ('gulp', 0.0010834236186348862), ('gaul', 0.0010834236186348862), ('sued', 0.0005417118093174431), ('quod', 0.0005417118093174431), ('quid', 0.0005417118093174431), ('gush', 0.0005417118093174431), ('guild', 0.0005417118093174431), ('guai', 0.0005417118093174431), ('grid', 0.0005417118093174431), ('glum', 0.0005417118093174431), ('gird', 0.0005417118093174431)]\n"
     ]
    }
   ],
   "source": [
    "k = Word(\"guud\")\n",
    "print(k.spellcheck())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('god', 0.7453798767967146), ('gun', 0.1293634496919918), ('mud', 0.07392197125256673), ('gut', 0.028747433264887063), ('gum', 0.012320328542094456), ('bud', 0.006160164271047228), ('guy', 0.004106776180698152)]\n"
     ]
    }
   ],
   "source": [
    "k = Word(\"gud\")\n",
    "print(k.spellcheck())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benefit', 'moral excellence or admirableness', 'that which is pleasing or valuable or useful', 'articles of commerce', 'having desirable or positive qualities especially those suitable for a thing specified', 'having the normally expected amount', 'morally admirable', 'deserving of esteem and respect', 'promoting or enhancing well-being', 'agreeable or pleasing', 'of moral excellence', 'having or showing knowledge and skill and aptitude', 'thorough', 'with or in a close or intimate relationship', 'financially sound', 'most suitable or right for a particular purpose', 'resulting favorably', 'exerting force or influence', 'capable of pleasing', 'appealing to the mind', 'in excellent physical condition', 'tending to promote physical well-being; beneficial to health', 'not forged', 'not left to spoil', 'generally admired', \"(often used as a combining form) in a good or proper or satisfactory manner or to a high standard (`good' is a nonstandard dialectal variant for `well')\", \"completely and absolutely (`good' is sometimes used informally for `thoroughly')\"]\n"
     ]
    }
   ],
   "source": [
    "k = Word(\"GOOD\")\n",
    "print(k.define())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(astronomy) any of the nine large celestial bodies in the solar system that revolve around the sun and shine by reflected light; Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune, and Pluto in order of their proximity to the sun; viewed from the constellation Hercules, all the planets rotate around the sun in a counterclockwise direction', 'a person who follows or serves another', 'any celestial body (other than comets or satellites) that revolves around a star']\n"
     ]
    }
   ],
   "source": [
    "z = Word(\"Planet\")\n",
    "print(z.define())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello everybody i am a programmer\n"
     ]
    }
   ],
   "source": [
    "#Capatalizes the first letter in the sentence or word\n",
    "u = Word(\"hello everybody i am a programmer\")\n",
    "print(u.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you all\n"
     ]
    }
   ],
   "source": [
    "#Capatalizes the first letter in the sentence or word\n",
    "y = Word(\"how are you all\")\n",
    "print(y.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "#Capatalizes the first letter in the sentence or word\n",
    "u = Word(\"hello\")\n",
    "print(u.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#test if the word is lower case  (result is a boolean)\n",
    "u = Word(\"HELLO\")\n",
    "print(u.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#test if the word is lower case  (result is a boolean)\n",
    "u = Word(\"Hello\")\n",
    "print(u.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#test if the word is lower case  (result is a boolean)\n",
    "u = Word(\"hello\")\n",
    "print(u.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#test if the word is lower case  (result is a boolean)\n",
    "u = Word(\"Great\")\n",
    "print(u.isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#test if the word is lower case  (result is a boolean)\n",
    "u = Word(\"GREAT\")\n",
    "print(u.isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'ares', 'stars']\n"
     ]
    }
   ],
   "source": [
    "#converts text to plural\n",
    "text = (\"cat are star\")\n",
    "cap = TextBlob(text)\n",
    "print(cap.words.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dogs', 'ares', 'animals']\n"
     ]
    }
   ],
   "source": [
    "#converts text to plural\n",
    "text = (\"dog are animal\")\n",
    "cap = TextBlob(text)\n",
    "print(cap.words.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'are', 'the', 'star', 'of', 'the', 'internet']\n"
     ]
    }
   ],
   "source": [
    "#converts text to singular\n",
    "text = (\"cats are the stars of the internets\")\n",
    "cap = TextBlob(text)\n",
    "print(cap.words.singularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'are', 'the', 'star', 'of', 'all', 'animal']\n"
     ]
    }
   ],
   "source": [
    "#converts text to singular\n",
    "text = (\"dogs are the stars of all animals\")\n",
    "cap = TextBlob(text)\n",
    "print(cap.words.singularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
